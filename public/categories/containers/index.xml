<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Containers on Agus Fahmi Aji Pramana&#39;s Blogging Site</title>
    <link>http://localhost:1313/categories/containers/</link>
    <description>Recent content in Containers on Agus Fahmi Aji Pramana&#39;s Blogging Site</description>
    <image>
      <title>Agus Fahmi Aji Pramana&#39;s Blogging Site</title>
      <url>http://localhost:1313/logo.svg</url>
      <link>http://localhost:1313/logo.svg</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/categories/containers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Containers 101</title>
      <link>http://localhost:1313/notes/containers-101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/notes/containers-101/</guid>
      <description>Containers with Docker Notes and Summary</description>
      <content:encoded><![CDATA[<h2 id="what-and-why">What and Why</h2>
<p>A container, powered by the containerization engine, is a standard unit of software that encapsulates the application code, runtime, system tools, system libraries, and settings necessary for programmers to build, ship, and run applications efficiently.</p>
<table>
  <thead>
      <tr>
          <th>Features</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Isolation and Allocation</td>
          <td>No way to define resources boundaries for apps in a physical server</td>
      </tr>
      <tr>
          <td>Server Utilization</td>
          <td>Not optimal because server tend to be either over-utilized or under-utilized</td>
      </tr>
      <tr>
          <td>Provisioning and Cost</td>
          <td>Requires long periods for provisioning resources and expensive maintenance costs</td>
      </tr>
      <tr>
          <td>Performance</td>
          <td>Constrained during peak workloads</td>
      </tr>
      <tr>
          <td>Portability</td>
          <td>Applications are not portable across multiple environments and operating systems</td>
      </tr>
      <tr>
          <td>Resiliency</td>
          <td>Complex, time-consuming and expensive</td>
      </tr>
      <tr>
          <td>Scalability</td>
          <td>Limited scalability and resiliency</td>
      </tr>
      <tr>
          <td>Automation</td>
          <td>Difficult to implement for multiple platforms</td>
      </tr>
  </tbody>
</table>
<h2 id="characteristics">Characteristics</h2>
<p>
  
  <input type="checkbox" id="zoomCheck-e8280" hidden />
  <label for="zoomCheck-e8280">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/container-characteristics.webp"
      alt="Container Characteristics"
       />
  </label>
</p>
<h2 id="challenges">Challenges</h2>
<ul>
<li>Security impacted if operating system affected</li>
<li>Difficult to manage thousands of containers</li>
<li>Complex to migrate legacy projects to container technology</li>
<li>Difficult to right-size containers for specific scenarios</li>
</ul>
<h2 id="vendors">Vendors</h2>
<ul>
<li><strong>Docker</strong> - Robust and most popular container platform today</li>
<li><strong>Podman</strong> - Daemon-less architecture providing more security than Docker containers</li>
<li><strong>LXC</strong> - Preferred for data-intensive apps and ops</li>
<li><strong>Vagrant</strong> - Offers highest levels of isolation on the running physical machine</li>
</ul>
<h2 id="docker">Docker</h2>
<p>Docker is an open platform, or engine, written in Go programming language, uses Linux kernel&rsquo;s features and namespaces technology to provide isolated workspace, where programmers can <strong>Develop -&gt; Ship -&gt; Run -&gt; Containers</strong>. Docker became popular because:</p>
<ul>
<li>Simple architecture</li>
<li>Scalability</li>
<li>Easy portability</li>
</ul>
<p>
  
  <input type="checkbox" id="zoomCheck-47b61" hidden />
  <label for="zoomCheck-47b61">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/container-creation-process.webp"
      alt="Container Creation Process"
       />
  </label>
</p>
<h2 id="docker-commands">Docker Commands</h2>
<p>
  
  <input type="checkbox" id="zoomCheck-6af87" hidden />
  <label for="zoomCheck-6af87">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/docker-commands.webp"
      alt="Docker Commands"
       />
  </label>
</p>
<h2 id="docker-objects">Docker Objects</h2>
<h3 id="dockerfile">Dockerfile</h3>
<p>is a text file that contains instructions needed to create an image.</p>
<ul>
<li>FROM - Defines base image, always begin from this instructions.</li>
<li>RUN - Executes arbitrary commands</li>
<li>CMD - Defines default command for container execution</li>
</ul>
<blockquote>
<p>CMD should always have one command instructions. If multiple CMD instructions then only the last command instruction will take effect.</p></blockquote>
<h3 id="image">Image</h3>
<blockquote>
<p>layers can be shared between images, which saves disk space and network bandwidth.</p></blockquote>
<p>
  
  <input type="checkbox" id="zoomCheck-10a73" hidden />
  <label for="zoomCheck-10a73">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/docker-image-layer.webp"
      alt="Docker Image Layer"
       />
  </label>
</p>
<h4 id="naming">Naming</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">      hostname/repository:tag
</span></span><span class="line"><span class="cl">        ^         ^        ^
</span></span><span class="line"><span class="cl">      /           <span class="p">|</span>          <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  Image       Container    Version
</span></span><span class="line"><span class="cl"> Registry      Images   or Variant of Image
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">e.g. docker.io/ubuntu:18.04
</span></span></code></pre></div><blockquote>
<p>The host name can be excluded using Docker CLI.</p></blockquote>
<h3 id="container">Container</h3>
<ul>
<li>is runnable instance of an image</li>
<li>can be created, stopped, started or deleted using the Docker API or CLI</li>
<li>can connect to multiple networks, attach storage, or create a new image based on its current state</li>
<li>is well isolated from other containers and its host machine</li>
</ul>
<h3 id="network">Network</h3>
<ul>
<li>Networks are used for the isolated containers communication</li>
</ul>
<h3 id="storage">Storage</h3>
<ul>
<li>Docker uses volumes and bind mounts to persist data even after a container stops</li>
</ul>
<h3 id="plugins">Plugins</h3>
<ul>
<li>Storage plugins provide the ability to connect to external storage platforms</li>
</ul>
<h2 id="docker-architecture">Docker Architecture</h2>
<p>consists of a Docker client, a Docker host, and a registry.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-6807b" hidden />
  <label for="zoomCheck-6807b">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/docker-architecture.webp"
      alt="Docker Architecture"
       />
  </label>
</p>
<ul>
<li>based on client-server architecture</li>
<li>provides a complete application environment</li>
<li>includes the client, the host, and the registry components</li>
<li>Docker host server include Docker daemon known as dockerd</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">Docker CLI or REST APIs -------&gt; Docker host server
</span></span><span class="line"><span class="cl">                  sends instructions
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Daemon &lt;----- Docker API requests or <span class="s2">&#34;docker run&#34;</span> commands
</span></span><span class="line"><span class="cl">       listens
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">The daemon ----------------&gt; to the registry
</span></span><span class="line"><span class="cl">    builds, runs, and distributes containers
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Registry ----------&gt; images <span class="o">(</span>either public or private<span class="o">)</span>
</span></span><span class="line"><span class="cl">          stores
</span></span></code></pre></div><h3 id="registry">Registry</h3>
<ul>
<li>stores and distributed images, public (Docker Hub), private (implemented for security).</li>
<li>registry locations are either hosted or self-hosted.</li>
</ul>
<p>
  
  <input type="checkbox" id="zoomCheck-a1a44" hidden />
  <label for="zoomCheck-a1a44">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/registry-process.webp"
      alt="Registry Process"
       />
  </label>
</p>
<h2 id="commands">Commands</h2>
<table>
  <thead>
      <tr>
          <th>Command</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>curl localhost</td>
          <td>Pings the application.</td>
      </tr>
      <tr>
          <td>docker build</td>
          <td>Builds an image from a Dockerfile.</td>
      </tr>
      <tr>
          <td>docker build . -t</td>
          <td>Builds the image and tags the image id.</td>
      </tr>
      <tr>
          <td>docker CLI</td>
          <td>Start the Docker command line interface.</td>
      </tr>
      <tr>
          <td>docker container rm</td>
          <td>Removes a container.</td>
      </tr>
      <tr>
          <td>docker images</td>
          <td>Lists the images.</td>
      </tr>
      <tr>
          <td>docker ps</td>
          <td>Lists the containers.</td>
      </tr>
      <tr>
          <td>docker ps -a</td>
          <td>Lists the containers that ran and exited successfully.</td>
      </tr>
      <tr>
          <td>docker pull</td>
          <td>Pulls the latest image or repository from a registry.</td>
      </tr>
      <tr>
          <td>docker push</td>
          <td>Pushes an image or a repository to a registry.</td>
      </tr>
      <tr>
          <td>docker run</td>
          <td>Runs a command in a new container.</td>
      </tr>
      <tr>
          <td>docker run -p</td>
          <td>Runs the container by publishing the ports.</td>
      </tr>
      <tr>
          <td>docker stop</td>
          <td>Stops one or more running containers.</td>
      </tr>
      <tr>
          <td>docker stop $(docker ps -q)</td>
          <td>Stops all running containers.</td>
      </tr>
      <tr>
          <td>docker tag</td>
          <td>Creates a tag for a target image that refers to a source image.</td>
      </tr>
      <tr>
          <td>docker –version</td>
          <td>Displays the version of the Docker CLI.</td>
      </tr>
      <tr>
          <td>exit</td>
          <td>Closes the terminal session.</td>
      </tr>
      <tr>
          <td>export MY_NAMESPACE</td>
          <td>Exports a namespace as an environment variable.</td>
      </tr>
      <tr>
          <td>git clone</td>
          <td>Clones the git repository that contains the artifacts needed.</td>
      </tr>
  </tbody>
</table>
<h2 id="ibm-specific-commands">IBM Specific Commands</h2>
<table>
  <thead>
      <tr>
          <th>Command</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>ibmcloud cr images</td>
          <td>Lists images in the IBM Cloud Container Registry.</td>
      </tr>
      <tr>
          <td>ibmcloud cr login</td>
          <td>Logs your local Docker daemon into IBM Cloud Container Registry.</td>
      </tr>
      <tr>
          <td>ibmcloud cr namespaces</td>
          <td>Views the namespaces you have access to.</td>
      </tr>
      <tr>
          <td>ibmcloud cr region-set</td>
          <td>Ensures that you are targeting the region appropriate to your cloud account.</td>
      </tr>
      <tr>
          <td>ibmcloud target</td>
          <td>Provides information about the account you’re targeting.</td>
      </tr>
      <tr>
          <td>ibmcloud version</td>
          <td>Displays the version of the IBM Cloud CLI.</td>
      </tr>
  </tbody>
</table>
]]></content:encoded>
    </item>
    <item>
      <title>Containers 201: Security in DevOps</title>
      <link>http://localhost:1313/notes/container-201-security-in-devops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/notes/container-201-security-in-devops/</guid>
      <description>Securing Containers in DevOps</description>
      <content:encoded><![CDATA[<h2 id="containers">Containers</h2>
<h3 id="under-the-hood">Under the Hood</h3>
<p>Cgroups (control groups) are a kernel mechanism for limiting and measuring the total resources used by a group of processes running on a system. For example, you can restrict CPU, memory, network, or I/O quotas using cgroups.</p>
<p>Namespaces are a kernel mechanism for limiting the visibility that a group of processes has over the rest of a system. For example, you can limit visibility to certain process trees, network interfaces, user IDs, or filesystem mounts.</p>
<blockquote>
<p>cgroups limit how much of a resource you can use whereas namespaces limit which resources you can use.</p></blockquote>
<h3 id="lxc-framework">LXC Framework</h3>
<p>LXC (Linux Containers) are an OS level virtualization method that allow running multiple isolated Linux containers on a host OS using a single Linux kernel. LXC (Linux Containers) uses the following kernel features to contain processes:</p>
<ul>
<li>
<p>LXC namespaces (IPC, Network, Mount, PID, User, UTS)</p>
<blockquote>
<p>Kernel version 4.10, there are six kinds of namespaces, IPC, Network, Mount, PID, User, UTS</p></blockquote>
</li>
<li>
<p>LXC cgroups (control groups)</p>
<blockquote>
<p>LXC cgroups framework provides Resource Limiting, Prioritization, Accounting, Control</p></blockquote>
</li>
<li>
<p>LXC security modules (AppArmor and SELinux profiles)</p>
<blockquote>
<p>Two most accepted modules in Linux Kernel are AppArmor and SELinux.</p></blockquote>
</li>
</ul>
<h3 id="lxc-containers">LXC Containers</h3>
<ul>
<li><strong>Privileged containers</strong> are defined as any container where the container UID 0 is mapped to the host’s UID 0.</li>
<li><strong>Unprivileged containers</strong> are safe by design. The container UID 0 is mapped to an unprivileged user outside of the container and only has extra rights on resources that it owns itself.</li>
</ul>
<h2 id="container-security">Container Security</h2>
<ul>
<li>Securing the container development pipeline and corresponding applications.</li>
<li>Securing the container deployment environment(s) and corresponding infrastructure.</li>
<li>Integrating with enterprise security tools and enhancing existing security policies and procedures.</li>
</ul>
<h3 id="challenges-to-devops">Challenges to DevOps</h3>
<ul>
<li><strong>Code Phase</strong> - use of third-party resources, GitHub repository is unavoidable</li>
<li><strong>Build Phase</strong> - Installing applications keeping default configuration, not implementing security safeguards or hardening controls.</li>
<li><strong>Test Phase</strong> - Deployed applications can be exploited through a variety of security testing methods.</li>
<li><strong>Deploy Phase</strong> - Exposing data in Docker files and embedded malware in container image.</li>
<li><strong>Operate Phase</strong> - Non-updated images, well-known vulnerability in dependencies, unrestricted admin access, unauthorized access.</li>
<li><strong>Monitor Phase</strong> - Hijacked repository, image registry and poisoned resources, exposed ports, Kubernetes/Docker API abuse</li>
</ul>
<h3 id="defense-in-depth-in-container">Defense in Depth in Container</h3>
<ul>
<li><strong>Cloud Provider</strong> is first layer involving supporting infrastructure, typically hosted by main cloud providers.</li>
<li><strong>Cluster</strong> allows to manage the workloads of nodes within a management layer are responsible for running application.</li>
<li><strong>Container</strong> third layer, static analysis of vulnerability in application container, image signing and enforcement to mitigate man-in-the-middle attacks.</li>
<li><strong>Code</strong> security awareness for engineers and developers.</li>
</ul>
<h4 id="securing-container-layer">Securing Container Layer</h4>
<ul>
<li>Docker Content Trust - builtin and integrates TUF using Notary, strong cryptographic guarantees over code.</li>
<li>Portieris - Kubernetes admission controller for enforcing content trust.</li>
<li>Project Calico - Open source networking and network security solution for containers, VMs, and native host-based workloads.</li>
</ul>
<h4 id="securing-code-layer">Securing Code Layer</h4>
<ul>
<li>Awareness of common vulnerabilities affecting this technology and way to test them.</li>
<li>Grant access to application over TLS only.</li>
<li>Limit port ranges of communication.</li>
<li>Don&rsquo;t hardcode secrets or passwords in source code and don&rsquo;t reuse.</li>
<li>Store secrets in secure repositories. Unsecure repo includes shared storage, unencrypted files, version control systems, S3 etc.</li>
<li>Use third party dependency security, e.g. GitHub security alerts scan and alert developers.</li>
<li>Perform static code analysis - scan codebases for common security errors.</li>
<li>Perform dynamic testing - using tools to exploit well-known attacks, OWASP Top Ten Project.</li>
<li>Perform secure API development.</li>
</ul>
<h3 id="docker">Docker</h3>
<p>Docker enables the organization to run, create, and manage containers on a single operating system.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-63105" hidden />
  <label for="zoomCheck-63105">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/docker.webp#center"
      alt="Docker Diagram"
       />
  </label>
</p>
<h3 id="kubernetes">Kubernetes</h3>
<p>Kubernetes is a container orchestration system for Docker containers, address container issues, provide scaling as needed.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-a8143" hidden />
  <label for="zoomCheck-a8143">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes.webp#center"
      alt="Kubernetes Diagram"
       />
  </label>
</p>
<h4 id="architecture">Architecture</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-37791" hidden />
  <label for="zoomCheck-37791">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/architecture.webp"
      alt="Kubernetes Architecture"
       />
  </label>
</p>
<h5 id="control-plane">Control Plane</h5>
<ul>
<li>One or More API Servers: Entry point for REST / <strong>kubectl</strong></li>
<li><strong>etcd</strong>: Distributed key/value store</li>
<li><strong>Controller-manager</strong>: Always evaluating current vs desired state</li>
<li><strong>Scheduler</strong>: Schedules pods to worker nodes</li>
</ul>
<h5 id="data-plane">Data Plane</h5>
<ul>
<li>Made up of worker nodes</li>
<li><strong>kubelet</strong>: Acts as a conduit between the API server and the node</li>
<li><strong>kube-proxy</strong>: Manages IP translation and routing</li>
</ul>
<h4 id="components-of-cluster">Components of Cluster</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-b320b" hidden />
  <label for="zoomCheck-b320b">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-cluster.webp"
      alt="Kubernetes Cluster"
       />
  </label>
</p>
<ul>
<li><strong>Node</strong> - common term for VMs and/or bare-metal servers that Kubernetes manages.</li>
<li><strong>Pod</strong> - basic unit of deployment in Kubernetes, collection of related Docker containers that need to coexist.</li>
</ul>
<h4 id="securing-the-components-of-the-cluster">Securing the Components of the Cluster</h4>
<ul>
<li>Use transport layer security (TLS) for all API traffic.</li>
<li>Implement API authentication and authorization can be infrastructure, like nodes, proxies, the scheduler, and volume plugins.</li>
<li>Limit resource usage on a cluster, resource quota, max/min size of resources like CPU, memory, or persistent disk a namespace can allocate.</li>
<li>Employ user permissions hardening as most application workloads need limited access to host resources (UID 0).</li>
<li>Restrict network access.</li>
<li>Restrict metadata access, the cloud platforms exposes metadata contain cloud credentials services locally to instances so running Kubernetes on cloud platform, limit permissions given to instance credentials, use network policies to restrict pod access metadata api.</li>
<li>Control which nodes, pods may access, use policies to separate workloads.</li>
<li>Restrict access to etcd write access equivalent to gaining root on entire cluster and read access can escalate quickly.</li>
<li>Enable audit logging of the cluster.</li>
<li>Don&rsquo;t use alpha or beta features in production clusters.</li>
<li>Rotate infrastructure credentials, shorter lifetime of secret, automate rotation.</li>
<li>Review third-party integration libraries and requested permissions.</li>
<li>Encrypt secrets at rest.</li>
</ul>
<h2 id="container-orchestration">Container Orchestration</h2>
<p>Container Orchestration means managing lifecycle of containers, especially in large, dynamic environments. It used used to deploy, scale, schedule and network applications. Some engineering teams container orchestration tasks are:</p>
<ul>
<li>Scaling up or down resources</li>
<li>Provisioning and deployment</li>
<li>Redundancy and availability</li>
<li>Expose singular points of access</li>
<li>Load balancing</li>
<li>Resource sharing</li>
<li>External exposure of services running in a container to the outside world</li>
<li>Health monitoring</li>
<li>Configuration of an application in relation to the containers running it</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.sans.org/reading-room/whitepapers/auditing/checklist-audit-docker-containers-37437">The SANS Institute’s checklist for auditing Docker-based containers</a></li>
<li><a href="https://www.trendmicro.com/vinfo/us/security/news/security-technology/container-security-examining-potential-threats-to-the-container-environment">The article “Container Security: Examining Potential Threats to the Container Environment”</a></li>
<li><a href="https://kubernetes.io/docs/concepts/security/overview/">Kubernetes Cloud Native Security</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/">Securing a Kubernetes cluster</a></li>
<li><a href="https://www.linuxjournal.com/content/everything-you-need-know-about-containers-part-iii-orchestration-kubernetes">Orchestration with Kubernetes</a></li>
<li><a href="https://www.cncf.io/announcement/2017/10/24/cncf-host-two-security-projects-notary-tuf-specification/">Notary</a></li>
<li><a href="https://success.docker.com/article/introduction-to-docker-content-trust">Docker Content Trust</a></li>
<li><a href="https://github.com/IBM/portieris">IBM Portieris</a></li>
<li><a href="https://web.mit.edu/rhel-doc/5/RHEL-5-manual/Deployment_Guide-en-US/ch-selinux.html">SELinux</a></li>
<li><a href="https://docs.projectcalico.org/v3.9/introduction/">Project Calico</a></li>
<li><a href="https://blog.newrelic.com/engineering/container-orchestration-explained/">What Is Container Orchestration?</a></li>
<li><a href="https://www.trendmicro.com/en_ie/business/products/hybrid-cloud/container.html">Security for Containers</a></li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Kubernetes 101</title>
      <link>http://localhost:1313/notes/kubernetes-101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/notes/kubernetes-101/</guid>
      <description>Kubernetes Notes</description>
      <content:encoded><![CDATA[<h2 id="orchestration">Orchestration</h2>
<p>Container orchestration automates the container lifecycle of containerized applications resulting in faster deployments, reduced errors, higher availability, and more robust security. The <strong>container lifecycle include</strong>:</p>
<ul>
<li>Deployment</li>
<li>Management</li>
<li>Scaling</li>
<li>Networking</li>
<li>Availability</li>
</ul>
<p>Container orchestration is a critical part of an organization&rsquo;s orchestration, automation, and response (SOAR) requirements. <strong>Some features</strong>:</p>
<ul>
<li>Defines container images and registry</li>
<li>Improves provisioning and deployment</li>
<li>Secure network connectivity</li>
<li>Ensures availability and performance</li>
<li>Manages scalability and load balancing</li>
<li>Resource allocation and scheduling</li>
<li>Rolling updates and roll backs</li>
<li>Conducting health checks and automated error handling</li>
</ul>
<p><strong>Benefits</strong> of Container Orchestration:</p>
<ul>
<li>Increased Productivity</li>
<li>Faster Deployment</li>
<li>Reduced Costs</li>
<li>Stronger Security</li>
<li>Easier Scaling</li>
<li>Faster Error Recovery</li>
</ul>
<h3 id="how-it-works">How it works?</h3>
<p>
  
  <input type="checkbox" id="zoomCheck-ac2b7" hidden />
  <label for="zoomCheck-ac2b7">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/how-container-orchestration-works.webp"
      alt="How Container Orchestration Works"
       />
  </label>
</p>
<ul>
<li>uses <strong>configuration files</strong> written in YAML or JSON uses to find resources, establish a network and store logs</li>
<li>automatically <strong>schedules the deployment</strong> of new container to a cluster, finds the right host based on predefined settings or restrictions</li>
<li><strong>manages the container&rsquo;s lifecycle</strong> based on specifications in the configuration file includes system parameters (like CPU and memory), and file parameters (like proximity and file metadata)</li>
<li><strong>supports scaling and enhances productivity</strong>, through automation</li>
</ul>
<h3 id="tools">Tools</h3>
<ul>
<li>Apache Mesos&rsquo;s <strong>Marathon</strong> framework - open-source cluster manager, scales container infrastructure by automating the bulk of management and monitoring tasks</li>
<li>HashiCorp&rsquo;s <strong>Nomad</strong> - free, open-source cluster management and scheduling tools, supports various app types on all major operating systems</li>
<li><strong>Docker Swarm</strong> - open-source container orchestration platform, automates deployment of containerized apps, specifically to work with Docker Engine and other Docker tools</li>
<li>zGoogle&rsquo;s <strong>Kubernetes</strong> - standard for open-source container orchestration platforms, robust feature set, broadly supported, maintained by Cloud Native Computing Foundation (CNCF)</li>
</ul>
<h2 id="kubernetes">Kubernetes</h2>
<ul>
<li>referred as (k8s), is system for automating deployment,scaling, and management of containerized applications.</li>
<li>automates a host of container management tasks including
<ul>
<li>deployment,</li>
<li>storage provisioning,</li>
<li>load balancing and scaling,</li>
<li>service discovery, and</li>
<li>“self-healing”— the ability to restart, replace or remove a failed container.</li>
</ul>
</li>
</ul>
<h3 id="is-not">Is Not</h3>
<ul>
<li>traditional, all-inclusive as a service (PaaS)</li>
<li>rigid or opinionated but a flexible model that supports a diverse variety of workloads and containerized applications.</li>
<li>does not provide CI/CD pipelines to deploy source code or build applications</li>
<li>does not prescribe logging, monitoring, or alerting solutions</li>
<li>does not provide built-in middleware, databases, or other services</li>
</ul>
<h3 id="capabilities">Capabilities</h3>
<ul>
<li><strong>Automated rollouts</strong> of changes to application or configuration, health monitoring, ensures instances are running, and <strong>rolling back</strong> changes</li>
<li><strong>Storage orchestration</strong> that mounts a chosen storage system including local storage, network storage, or public cloud</li>
<li><strong>Horizontal scaling</strong> of workloads based on metrics, or via commands</li>
<li><strong>Automated bin packing</strong> that increases utilization and cost savings using a mix of critical and best-effort workloads. Automated bin packing performs container auto-placement based on resource requirements and conditions without sacrificing high availability (HA)</li>
<li><strong>Secret and configuration management</strong> of sensitive information including passwords, OAuth tokens, and SSH keys, and handles deployments and updates to secrets and configuration without rebuilding images</li>
<li>assigns both <strong>dual-stack IPv4 and IPv6 addresses</strong> to Pods and Services</li>
<li>manages <strong>batch execution</strong> and continuous integration workloads and automatically replaces failed containers</li>
<li><strong>self-heals</strong> failing or unresponsive containers, exposes containers to clients only if healthy and running</li>
<li><strong>discovers</strong> Pods using IP addresses or a DNS name, and <strong>load balances</strong> traffic for better performance and high availability</li>
<li>easily <strong>extensible</strong> by adding or providing additional features to Kubernetes cluster without modifying source code</li>
</ul>
<h3 id="concepts">Concepts</h3>
<p>
  
  <input type="checkbox" id="zoomCheck-6b7f9" hidden />
  <label for="zoomCheck-6b7f9">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-concept-part-one.webp"
      alt="Kubernetes Concept Part 1"
       />
  </label>


  
  <input type="checkbox" id="zoomCheck-f29a8" hidden />
  <label for="zoomCheck-f29a8">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-concept-part-two.webp"
      alt="Kubernetes Concept Part 2"
       />
  </label>
</p>
<h3 id="ecosystem">Ecosystem</h3>
<p>
  
  <input type="checkbox" id="zoomCheck-52f9f" hidden />
  <label for="zoomCheck-52f9f">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-ecosystem.webp"
      alt="Kubernetes Ecosystem"
       />
  </label>
</p>
<h3 id="architecture">Architecture</h3>
<ul>
<li>A deployment of Kubernetes is called a Kubernetes cluster, is a cluster of nodes that runs containerized applications</li>
<li>Each cluster has <strong>one master node</strong> (the Kubernetes Control Plane) and <strong>one or more worker nodes</strong></li>
</ul>
<h4 id="control-plane">Control Plane</h4>
<ul>
<li>The control plane maintains the intended cluster state by <strong>making decisions</strong> about the cluster and detecting and responding to events in the cluster</li>
</ul>
<blockquote>
<p>An example of a decision made by the control plane is the <strong>scheduling of workloads</strong>. An example of responding to an event is <strong>creating new resources</strong> when an application is deployed.</p></blockquote>
<p>
  
  <input type="checkbox" id="zoomCheck-42a7b" hidden />
  <label for="zoomCheck-42a7b">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-control-pane.webp"
      alt="Kubernetes Control Pane"
       />
  </label>
</p>
<h5 id="kube-api-server">kube-api-server</h5>
<ul>
<li>the <strong>Kubernetes API server</strong> exposes the Kubernetes API. The <strong>API server serves as the front-end</strong> for the control plane</li>
<li>all <strong>communication</strong> in the cluster utilizes this API, <strong>kube-apiserver</strong> which is designed to scale horizontally—by deploying more instances and balance traffic between them</li>
</ul>
<blockquote>
<p>An example the Kubernetes API server accepts commands to view or change the state of the cluster.</p></blockquote>
<h5 id="etcd">etcd</h5>
<ul>
<li>highly available, distributed key value store that contains all the cluster data</li>
<li>stores deployment configuration data, desired state, and meta data in a way that can be accessed in a common location</li>
<li>defines the state in a Kubernetes cluster, and the system works to bring the actual state to match the desired state</li>
</ul>
<h5 id="kube-scheduler">kube-scheduler</h5>
<ul>
<li>assigns newly created Pods to nodes, means it determines where workloads should run within the cluster</li>
<li>selects the most optimal node according to Kubernetes scheduling principles, configuration options, and available resources</li>
</ul>
<h5 id="kube-controller-manager">kube-controller manager</h5>
<ul>
<li>runs all the controller processes that monitor the cluster state</li>
<li>ensure the actual state of a cluster matches the desired state</li>
</ul>
<h5 id="cloud-controller-manager">cloud-controller manager</h5>
<ul>
<li>runs controllers that interact with the underlying cloud providers</li>
<li>effectively link clusters into a cloud provider’s API</li>
<li>allows both Kubernetes and the cloud providers to evolve freely without introducing dependencies on the other</li>
</ul>
<h4 id="worker-nodes">Worker Nodes</h4>
<ul>
<li>are the worker machines in a Kubernetes cluster, user applications are run on nodes, can be virtual or physical machines</li>
<li>are not created by Kubernetes itself, but rather by the cloud provider, allowing Kubernetes to run on a variety of infrastructures</li>
<li>are then managed by the control plane and contain the services necessary to run applications</li>
<li>include pods, which are the smallest deployment entity in Kubernetes; pods include one or more containers</li>
<li>containers share all the resources of the node and can communicate among themselves</li>
</ul>
<p>
  
  <input type="checkbox" id="zoomCheck-42bc8" hidden />
  <label for="zoomCheck-42bc8">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubernetes-worker-nodes.webp"
      alt="Kubernetes Worker Node"
       />
  </label>
</p>
<h5 id="kubelet">kubelet</h5>
<ul>
<li>is the most important component of a worker node, this controller communicates with the kube-apiserver to receive new and modified pod specifications</li>
<li>ensure that the pods and their associated containers are running as desired</li>
<li>reports to the control plane on the pods’ health and status</li>
<li>to start a pod, the kubelet uses the container runtime</li>
</ul>
<h5 id="container-runtime">Container runtime</h5>
<ul>
<li>is responsible for downloading images and running containers</li>
<li>rather than providing a single container runtime, Kubernetes implements a Container Runtime Interface that permits pluggability of the container runtime</li>
<li>Docker is likely the best-known runtime, Podman and Cri-o are two other commonly used container runtimes</li>
</ul>
<h5 id="kube-proxy">kube-proxy</h5>
<ul>
<li>is a network proxy that runs on each node in a cluster</li>
<li>maintains network rules that allow communication to Pods running on nodes — in other words, communication to workloads running on your cluster</li>
<li>This communication can come from within or outside of the cluster</li>
</ul>
<h3 id="objects-terms">Objects Terms</h3>
<ul>
<li><strong>software object</strong> - a bundle of data that has an identity, a state, and a behavior.
<ul>
<li>Example include variables, data structures, and specific functions.</li>
</ul>
</li>
<li><strong>entity</strong> - a person, place, or thing with an identity and associated data.
<ul>
<li>Example in banking, a customer account is an entity.</li>
</ul>
</li>
<li><strong>persistent</strong> - that lasts even if there is a server failure or network attack.
<ul>
<li>Example is persistent storage.</li>
</ul>
</li>
</ul>
<h3 id="kubernetes-objects">Kubernetes Objects</h3>
<ul>
<li>Kubernetes objects are persistent entities. Example: <strong>Pods</strong>, <strong>Namespaces</strong>, <strong>ReplicaSets</strong>, <strong>Deployments</strong>, and more.</li>
<li>Kubernetes objects consist of two main fields:
<ul>
<li><strong>object spec</strong> - provided by user and defines desired state</li>
<li><strong>status</strong> - provided by Kubernetes and defines current state</li>
</ul>
</li>
<li>Kubernetes works towards matching the current state to the desired state.</li>
<li>To work with these objects, use the Kubernetes API directly with the client libraries, and the kubectl command-line interface, or both</li>
</ul>
<h4 id="labels-and-selectors">Labels and selectors</h4>
<ul>
<li>Labels are key/value pairs attached to objects.
<ul>
<li>Intended for identification of objects.</li>
<li>Not unique. Many objects can have the same labels.</li>
<li>Helps to organize and group objects.</li>
</ul>
</li>
<li>Label selectors are the core grouping method in Kubernetes.
<ul>
<li>Identify and group a set of objects.</li>
</ul>
</li>
</ul>
<h4 id="namespaces-and-names">Namespaces and names</h4>
<ul>
<li>Namespaces provide a mechanism for isolating groups of resources within a single cluster.</li>
<li>This is useful when teams share a cluster for cost-saving purposes or for maintaining multiple projects in isolation.</li>
<li>There are different patterns of working with namespaces.
<ul>
<li>There may be only one namespace for a user who works with one team which only has one project that is deployed into a cluster.</li>
<li>Alternatively, there may be many teams or projects, or users with different needs, where additional namespaces may be created.</li>
</ul>
</li>
<li>Namespaces provide a scope for the names of objects
<ul>
<li>Each object must have a unique name</li>
<li>Names are uniques for that resource type within that namespace</li>
</ul>
</li>
</ul>
<h4 id="pods">Pods</h4>
<ul>
<li>is the simplest unit in Kubernetes</li>
<li>represents a process or a single instance of an application running in the cluster.</li>
<li>encapsulates one or more containers</li>
<li>replicating a pod serves to scale applications horizontally</li>
<li>YAML files are used to define the objects that you want to create.</li>
<li>The YAML files shown defines a simple pod.</li>
<li>A PodSpec must contain at least one container.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w"> </span><span class="c"># kind of object to be created</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w"> </span><span class="c"># provides the appropriate fields for the object</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"> </span><span class="c"># container and will run in this Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w"> </span><span class="c"># name of container</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx:1.7.9</span><span class="w"> </span><span class="c"># image that will run in Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">ports</span><span class="p">:</span><span class="w"> </span><span class="c"># port that container exposes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span></code></pre></div><h4 id="replicaset">ReplicaSet</h4>
<ul>
<li>is a set of identical running replicas of a Pod that are horizontally scale</li>
<li>the configuration files for a ReplicaSet and a Pod are different from each other</li>
<li>the replicas field specifies the number of replicas that should be running at any given time.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ReplicaSet</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-replicaset</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">replica</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="c"># creates/deletes Pods to meet the desired number of replicas</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w"> </span><span class="c"># selector to identify which pods it can acquire</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w"> </span><span class="c"># same as template labels below</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="c"># defines the Pods that should be created by the ReplicaSet</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w"> </span><span class="c"># same as matchLabels above</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx:1.7.9</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span></code></pre></div><blockquote>
<p><em>Note</em>: Creating ReplicaSets directly is not recommended. Instead, create a Deployment, which is a higher-level concept that manages ReplicaSets and offers more features and better control.</p></blockquote>
<h4 id="deployment">Deployment</h4>
<ul>
<li>is a higher-level object that provides updates for both Pods and ReplicaSets.
<ul>
<li>run multiple replicas of an application using ReplicaSets</li>
<li>are suitable for stateless applications</li>
</ul>
</li>
<li>for stateful applications, Stateful Sets are used</li>
<li>One key feature provided by Deployments but not by ReplicaSets is rolling updates</li>
<li>A rolling update scales up a new version to the appropriate number of replicas and scales down the old version to zero replicas</li>
<li>The ReplicaSet ensures that the appropriate number of Pods exist, while the Deployment orchestrates the roll out of a new version</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx:1.7.9</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span></code></pre></div><h4 id="service">Service</h4>
<ul>
<li>is a REST object, like Pods</li>
<li>are a logical abstraction for a set of Pods in a cluster</li>
<li>provide policies for accessing the Pods and cluster</li>
<li>act as a load balancer across the Pods</li>
<li>is assigned a unique IP address for accessing applications deployed on Pods</li>
<li>eliminates the need for a separate service discovery process.</li>
</ul>
<p><strong>Service Properties</strong>:</p>
<ul>
<li>supports multiple protocols such as TCP, which is the default protocol, UDP, and others</li>
<li>supports multiple port definitions
<ul>
<li>The port number with the same name can vary in each backend Pod</li>
</ul>
</li>
<li>can have an optional selector and can optionally map incoming ports to a targetPort</li>
</ul>
<p><strong>Why a Service is needed</strong>:</p>
<ul>
<li>is needed because Pods in a cluster are volatile, can be destroyed and new Pods can be created at any time</li>
<li>this volatility leads to discoverability issues because of changing IP addresses</li>
<li>it keeps track of Pod changes and exposes a single IP address or a DNS name</li>
<li>utilizes selectors to target a set of Pods</li>
</ul>
<p>
  
  <input type="checkbox" id="zoomCheck-8f7af" hidden />
  <label for="zoomCheck-8f7af">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/service-application.webp"
      alt="Service Application"
       />
  </label>
</p>
<h5 id="service-types">Service types</h5>
<h6 id="clusterip">ClusterIP</h6>
<p>
  
  <input type="checkbox" id="zoomCheck-e38bf" hidden />
  <label for="zoomCheck-e38bf">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/cluster-ip-service.webp"
      alt="ClusterIP Service"
       />
  </label>
</p>
<ul>
<li>is the default and most common service type</li>
<li>assigns a cluster-internal IP address to the ClusterIP Service that makes the Service only reachable within the cluster.</li>
<li>cannot make requests to Service from outside the cluster.</li>
<li>You can set the ClusterIP address in the Service definition file</li>
<li>provides Inter-service communication within the cluster</li>
</ul>
<h6 id="nodeport">NodePort</h6>
<p>
  
  <input type="checkbox" id="zoomCheck-fc8e0" hidden />
  <label for="zoomCheck-fc8e0">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/node-port-service.webp"
      alt="NodePort Service"
       />
  </label>
</p>
<ul>
<li>an extension of ClusterIP Service</li>
<li>creates and routes the incoming requests automatically to the ClusterIP Service</li>
<li>exposes the Service on each Node’s IP address at a static port</li>
<li>exposes a single Service with no load-balancing requirements for multiple services.</li>
</ul>
<blockquote>
<p><em>Note</em> that for security purposes, production use is not recommended.</p></blockquote>
<h6 id="external-load-balancer-elb">External Load Balancer (ELB)</h6>
<p>
  
  <input type="checkbox" id="zoomCheck-da7a2" hidden />
  <label for="zoomCheck-da7a2">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/elb-service.webp"
      alt="ELB Service"
       />
  </label>
</p>
<ul>
<li>an extension of the NodePort Service</li>
<li>creates NodePort and ClusterIP Services automatically</li>
<li>integrates and automatically directs traffic to the NodePort Service with a cloud provider&rsquo;s ELB</li>
<li>To expose a Service to the Internet, you need a new ELB with an IP address</li>
<li>You can use a cloud provider’s ELB to host your cluster.</li>
</ul>
<h6 id="external-name">External Name</h6>
<p>
  
  <input type="checkbox" id="zoomCheck-4b62b" hidden />
  <label for="zoomCheck-4b62b">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/external-name-service.webp"
      alt="External Name Service"
       />
  </label>
</p>
<ul>
<li>maps to a DNS name and not to any selector</li>
<li>requires a <code>spec.externalName</code> parameter</li>
<li>maps the Service to the contents of the externalName field that returns a CNAME record and its value</li>
<li>can use an External name to create a Service that represents external storage and enable Pods from different namespaces to talk to each other</li>
</ul>
<h4 id="ingress">Ingress</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-7281b" hidden />
  <label for="zoomCheck-7281b">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/ingress.webp"
      alt="Ingress"
       />
  </label>
</p>
<ul>
<li>is an API object that, when combined with a controller, provides routing rules to manage external users’ access to multiple services in a Kubernetes cluster</li>
<li>in production, Ingress exposes applications to the Internet via port 80 (for HTTP) or port 443 (for HTTPS)</li>
<li>while the cluster monitors Ingress, an external Load Balancer is expensive and is managed outside the cluster</li>
<li>acts as a supervisor for external access, exposing routes from outside the cluster to internal services</li>
<li>adheres to rules defined on the Ingress resource to regulate traffic routing.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Feature</th>
          <th>Ingress Objects</th>
          <th>Ingress Controllers</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Definition</td>
          <td>API object managing external access to services</td>
          <td>Cluster resource implementing rules specified by Ingress</td>
      </tr>
      <tr>
          <td>Primary Function</td>
          <td>Regulates external access routing</td>
          <td>Implements rules, fulfilling the Ingress</td>
      </tr>
      <tr>
          <td>Configuration Source</td>
          <td>Rules defined on the Ingress resource</td>
          <td>Reads and processes information from the Ingress object</td>
      </tr>
      <tr>
          <td>Traffic Handling</td>
          <td>Manages HTTP and HTTPS routes</td>
          <td>Utilizes load balancer, configures frontends for traffic</td>
      </tr>
      <tr>
          <td>Activation</td>
          <td>Active upon configuration with Ingress resource</td>
          <td>Must be explicitly running for Ingress to function</td>
      </tr>
      <tr>
          <td>Handling Protocols</td>
          <td>Focused on HTTP and HTTPS</td>
          <td>Implements rules for various protocols and ports</td>
      </tr>
      <tr>
          <td>Automatic Startup</td>
          <td>Activated with configuration</td>
          <td>Requires explicit activation in the cluster</td>
      </tr>
      <tr>
          <td>Analogy</td>
          <td>Traffic rule set for the cluster</td>
          <td>Executor, similar to Nginx instance handling rules</td>
      </tr>
  </tbody>
</table>
<h4 id="daemonset">DaemonSet</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-5fe3f" hidden />
  <label for="zoomCheck-5fe3f">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/daemon-set.webp"
      alt="DaemonSet"
       />
  </label>
</p>
<ul>
<li>is an object that makes sure that Nodes run a copy of a Pod</li>
<li>As nodes are added to a cluster, Pods are added to the nodes</li>
<li>Pods are garbage collected when removed from a cluster</li>
<li>If you delete a DaemonSet, all Pods are removed</li>
<li>are ideally used for storage, logs, and monitoring nodes</li>
</ul>
<h4 id="statefulset">StatefulSet</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-6362c" hidden />
  <label for="zoomCheck-6362c">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/stateful-set.webp"
      alt="StatefulSet"
       />
  </label>
</p>
<ul>
<li>is an object that manages stateful applications</li>
<li>manages deployment and scaling of Pods</li>
<li>provides guarantees about the ordering and uniqueness of Pods</li>
<li>maintains a sticky identity for each Pod request</li>
<li>provides persistent storage volumes for your workloads</li>
</ul>
<h4 id="job">Job</h4>
<p>
  
  <input type="checkbox" id="zoomCheck-95d48" hidden />
  <label for="zoomCheck-95d48">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="job.webp"
      alt="Job"
       />
  </label>
</p>
<ul>
<li>job creates Pods and tracks the Pod completion process</li>
<li>are retried until completed</li>
<li>Deleting a job will remove the created Pods</li>
<li>Suspending a Job will delete its active Pods until the job resumes</li>
<li>can run several Pods in parallel</li>
<li>a CronJob is regularly used to create Jobs on an iterative schedule</li>
</ul>
<h3 id="kubectl---the-kubernetes-command-line-tool">Kubectl - The Kubernetes Command Line Tool</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl <span class="o">[</span>command<span class="o">]</span> <span class="o">[</span>type<span class="o">]</span> <span class="o">[</span>name<span class="o">]</span> <span class="o">[</span>flags<span class="o">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="o">[</span>command<span class="o">]</span> <span class="o">=</span> operation performed <span class="o">(</span>create, get, apply, delete<span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="o">[</span>type<span class="o">]</span>    <span class="o">=</span> resource <span class="nb">type</span> <span class="o">(</span>pod, deployment, replicaset<span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="o">[</span>name<span class="o">]</span>    <span class="o">=</span> resource name <span class="o">(</span><span class="k">if</span> applicable<span class="o">)</span>
</span></span><span class="line"><span class="cl">  <span class="o">[</span>flags<span class="o">]</span>   <span class="o">=</span> special options or modifiers that override default values
</span></span></code></pre></div><p>
  
  <input type="checkbox" id="zoomCheck-0e069" hidden />
  <label for="zoomCheck-0e069">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/kubectl-command.webp"
      alt="Kubectl Commands"
       />
  </label>
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get services
</span></span><span class="line"><span class="cl">kubectl get pods --all-namespaces
</span></span><span class="line"><span class="cl">kubectl get deployment my-dep
</span></span><span class="line"><span class="cl">kubectl get pods -o wide
</span></span></code></pre></div><p>Key command types:</p>
<ul>
<li>Imperative commands</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># No audit trails</span>
</span></span><span class="line"><span class="cl">kubectl run nginx --image nginx
</span></span></code></pre></div><ul>
<li>Imperative object configuration</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Inconsistency if changed configuration aren&#39;t merged</span>
</span></span><span class="line"><span class="cl">kubectl create -f nginx.yaml
</span></span></code></pre></div><ul>
<li>Declarative object configuration</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># operation are identified by Kubectl, not the user</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ideal for production systems</span>
</span></span><span class="line"><span class="cl">kubectl apply -f nginx/
</span></span></code></pre></div><h3 id="kubernetes-anti-patterns">Kubernetes Anti-patterns</h3>
<h4 id="avoid-baking-configuration-in-container-images">Avoid baking configuration in container images</h4>
<p>Containers offer the advantage of using a consistent image throughout the production process. To achieve adaptability across different environments, building images without embedding configuration directly into containers is essential.</p>
<p><strong>Issue:</strong> Problems arise when images contain environment-specific artifacts that deviate from the tested version, necessitating image rebuilds and risking inadequately tested versions in production. Identification of environment-dependent container images involves spotting features like hardcoded IP addresses, passwords, and environment-specific prefixes.</p>
<p><strong>Best practice:</strong> Create generic images independent of specific runtime settings. Containers enable the consistent use of a single image throughout the software lifecycle, promoting simplicity and efficiency.</p>
<h4 id="separate-application-and-infrastructure-deployment">Separate application and infrastructure deployment</h4>
<p>Infrastructure as Code (IaC) allows defining and deploying infrastructure like writing code. While deploying infrastructure through a pipeline is advantageous, separating infrastructure and application deployment is crucial.</p>
<p><strong>Issue:</strong> Using a single pipeline for both infrastructure and application deployment leads to resource and time wastage, especially when changes in application code outpace infrastructure changes.</p>
<p><strong>Best practice:</strong> Split infrastructure and application deployment into separate pipelines to optimize efficiency and resource utilization.</p>
<h4 id="eliminate-specific-order-in-deployment">Eliminate specific order in deployment</h4>
<p>Maintaining application stability despite delays in dependencies is crucial in container orchestration. Unlike traditional fixed startup orders, Kubernetes and containers initiate components simultaneously.</p>
<p><strong>Issue:</strong> Challenges arise when poor network latency disrupts communication, potentially causing pod crashes or temporary service unavailability.</p>
<p><strong>Best practice:</strong> Proactively anticipate failures, establish frameworks to minimize downtime, and adopt strategies for simultaneous component initiation to enhance application resilience.</p>
<h4 id="set-memory-and-cpu-limits-for-pods-problem">Set memory and CPU limits for pods problem</h4>
<p>The default Kubernetes setting without specified resource limits allows an application to potentially monopolize the entire cluster, causing disruptions.</p>
<p><strong>Best practice:</strong> Establish resource limits for all applications, conduct a thorough examination of each application&rsquo;s behavior under various conditions, and strike the right balance to optimize cluster performance.</p>
<h4 id="avoid-pulling-the-latest-tag-in-production-problem">Avoid pulling the latest tag in production problem</h4>
<p>Using the &ldquo;latest&rdquo; tag in production leads to unintended pod crashes as images are pulled down sporadically, lacking specificity.</p>
<p><strong>Best practice:</strong> Use specific and meaningful image tags, maintain the immutability of container images, store data outside containers in persistent storage, and avoid modifying containers post-deployment for safer and more repeatable deployments.</p>
<h4 id="segregate-production-and-non-production-workloads-problem">Segregate production and non-production workloads problem</h4>
<p>Relying on a single cluster for all operational needs poses challenges. Security concerns arise from default permissions and complications with non-namespaced Kubernetes resources.</p>
<p><strong>Best practice:</strong> Establish a second cluster exclusively for production purposes, avoiding complexities associated with multi-tenancy. Maintain at least two clusters—one for production and one for non-production.</p>
<h4 id="refrain-from-ad-hoc-deployments-with-kubectl-editpatch-problem">Refrain from ad-hoc deployments with kubectl edit/patch problem</h4>
<p>Configuration drift occurs when multiple environments deviate due to unplanned deployments or changes, leading to failed deployments.</p>
<p><strong>Best practice:</strong> Conduct all deployments through Git commits for comprehensive history, precise knowledge of cluster contents, and easy recreation or rollback of environments.</p>
<h4 id="implement-health-checks-with-liveness-and-readiness-probes-problem">Implement health checks with liveness and readiness probes problem</h4>
<p>Neglecting health checks can lead to various issues. Overly complex health checks with unpredictable timings can cause internal denial-of-service attacks within the cluster.</p>
<p><strong>Best practice:</strong> Configure health probes for each container, use liveness and readiness probes, and prioritize robust health checks for reliable application responsiveness.</p>
<h4 id="prioritize-secret-handling-and-use-vault-problem">Prioritize secret handling and use vault problem</h4>
<p>Embedding secrets directly into containers is poor practice. Using multiple secret handling methods or complex injection mechanisms can complicate local development and testing.</p>
<p><strong>Best practice:</strong> Use a consistent secret handling strategy, consider HashiCorp Vault, handle secrets uniformly across environments, and pass them to containers during runtime for enhanced resilience and security.</p>
<h4 id="use-controllers-and-avoid-running-multiple-processes-per-container-problem">Use controllers and avoid running multiple processes per container problem</h4>
<p>Directly using pods in production poses limitations. Pods lack durability, automatic rescheduling, and data retention guarantees. Running multiple processes in a single container without controllers can lead to issues.</p>
<p><strong>Best practice:</strong> Utilize Deployment with a replication factor, define one process per container, use multiple containers per pod if necessary, and leverage workload resources like Deployment, Job, or StatefulSet for reliability and scalability.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Kubernetes 201: Managing Apps</title>
      <link>http://localhost:1313/notes/kubernetes-201-managing-applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/notes/kubernetes-201-managing-applications/</guid>
      <description>Managing Applications with Kubernetes Notes</description>
      <content:encoded><![CDATA[<h2 id="replicaset">ReplicaSet</h2>
<ul>
<li>ensures the right number of pods are always up and running</li>
<li>provide high availability through redundancy</li>
<li>adds or deletes pods for scaling</li>
<li>always tries to match the actual state of the replicas to the desired state</li>
<li>replaces failing pods or deletes additional pods to maintain the desired state</li>
<li>supersedes ReplicaControllers</li>
<li>Deployments manage ReplicaSets, send pods declarative updates</li>
</ul>
<h3 id="create-replicaset-from-scratch">Create ReplicaSet from scratch</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># replicaset.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ReplicaSet</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">paulbouwer/hello-kubernets:1.5</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">              </span><span class="nt">-containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Outputs ReplicaSet was created</span>
</span></span><span class="line"><span class="cl">kubectl create -f replicaset.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># Confirm by using &#34;get pods&#34;</span>
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl"><span class="c1"># Output shows details about ReplicaSet and pod created</span>
</span></span><span class="line"><span class="cl">kubectl get rs
</span></span></code></pre></div><blockquote>
<p>Note: Creating a Deployment that includes a ReplicaSet is recommended over creating a standalone ReplicaSet.</p></blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Create deployment</span>
</span></span><span class="line"><span class="cl">kubectl create -f deployment.yaml
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl">kubectl get deploy
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Scale deployment</span>
</span></span><span class="line"><span class="cl">kubectl scale deploy hello-kubernetes --replicas<span class="o">=</span><span class="m">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Should shows 3 pods running</span>
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Delete pod</span>
</span></span><span class="line"><span class="cl">kubectl delete pod hello-kubernetes-2324343-5mflw
</span></span><span class="line"><span class="cl"><span class="c1"># Here desired state (--replicas=3) does not</span>
</span></span><span class="line"><span class="cl"><span class="c1"># match the actual state [running pods=2]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and deleted pod replaced by new one</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create pod extra pod</span>
</span></span><span class="line"><span class="cl">kubectl create pod hello-kubernetes-122323
</span></span><span class="line"><span class="cl"><span class="c1"># Here desired state (--replicas=3) does not</span>
</span></span><span class="line"><span class="cl"><span class="c1"># match the actual state [running pods=4]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and new pod is marked for deletion and removed automatically</span>
</span></span></code></pre></div><h2 id="autoscaling">Autoscaling</h2>
<ul>
<li>ReplicaSets provide a good start for scaling, but you don’t always want 10 instances of your resource running.</li>
<li>Kubernetes autoscaling helps optimize resource usage and costs by automatically scaling a cluster in line with demand as needed.</li>
<li>Kubernetes enables autoscaling at two different layers:
<ul>
<li>the cluster or node level</li>
<li>the pod level.</li>
</ul>
</li>
<li>Three types of autoscalers are available in Kubernetes:
<ul>
<li>The Horizontal Pod Autoscaler (or HPA)</li>
<li>Vertical Pod Autoscaler (or VPA)</li>
<li>Cluster Autoscaler (or CA)</li>
</ul>
</li>
</ul>
<p>To create autoscaling:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl">kubectl get rs
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl autoscale deploy hello-kubernetes --min<span class="o">=</span><span class="m">2</span> --max<span class="o">=</span><span class="m">5</span> --cpu-percent<span class="o">=</span><span class="m">50</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl describe rs hello-kubernetes-&lt;hash&gt;
</span></span></code></pre></div><ul>
<li>List the current number or state of pods.</li>
<li>A ReplicaSet is automatically created when you create a deployment. In order to autoscale, you simply use the autoscale command with the requisite attributes.</li>
<li>Min is the number of minimum pods – notice that we have changed the value of “Min” to 2.</li>
<li>Max is the number of maximum pods.</li>
<li>CPU-percent acts as a trigger that tells the system to create a new pod when the CPU usage reaches 50% across the cluster.</li>
<li>In the background, the deployment still uses the ReplicaSet to scale up and down.</li>
<li>The describe command shows the number of replicas in the &ldquo;autoscaled&rdquo; ReplicaSet.</li>
</ul>
<h3 id="the-horizontal-pod-autoscaler-or-hpa">The Horizontal Pod Autoscaler (or HPA)</h3>
<ul>
<li><strong>adjusts</strong> the number of replicas of an application by increasing or decreasing the number of pods.</li>
<li>automatically updates a workload resource (like a deployment) by horizontally scaling the workload to match the demand</li>
<li>Horizontal scaling, or “scaling out,” automatically increases or decreases the number of running pods as application usage changes.</li>
<li>uses a cluster operator that sets targets for metrics like CPU or memory utilization and the maximum and minimum desired number of replicas</li>
<li>even though you can create an HPA autoscaler from scratch, you should use the autoscale command instead.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get hpa
</span></span></code></pre></div><p>For example,</p>
<p>
  
  <input type="checkbox" id="zoomCheck-fe0a1" hidden />
  <label for="zoomCheck-fe0a1">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/hpa-graph.webp"
      alt="HPA Graph"
       />
  </label>
</p>
<ul>
<li>the system load is low early in the morning, so one pod is sufficient. The HPA autoscales the workload resource to meet usage demand.</li>
<li>By 11am, peak load drives a need for three pods, so the HPA autoscales the workload resource to meet usage demand.</li>
<li>Usage drops in the afternoon, so the third pod is marked for deletion and removed.</li>
<li>And usage drops even lower by 5pm, so another pod is marked for deletion and removed.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># another way to enable autoscaling is to manually</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c"># create the HPA object from a YAML file.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoScaler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w"> </span><span class="c"># can set the minimum and maximum number of pods.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="c"># The CPU-percent flag shows up as “targetCPUUtilizationPercentage”.</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">targetCPUUtilizationPercentage</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span></code></pre></div><h3 id="vertical-pod-autoscaler-or-vpa">Vertical Pod Autoscaler (or VPA)</h3>
<ul>
<li><strong>adjusts</strong> the resource requests and limits of a container by increasing or decreasing the resource size or speed of the pods.</li>
<li>A best practice is to scale horizontally, but there are some services you may want to run in a cluster where horizontal scaling is impossible or not ideal.</li>
<li>Vertical scaling, or “scaling up,” refers to adding more resources to an existing machine.</li>
<li>lets you scale a service vertically within a cluster.</li>
<li>uses a cluster operator sets targets for metrics like CPU or memory utilization, similar to an HPA.</li>
<li>The cluster then reconciles the size of the service’s pod or pods based on their current usage and the desired target.</li>
</ul>
<p>For example,</p>
<p>
  
  <input type="checkbox" id="zoomCheck-074d3" hidden />
  <label for="zoomCheck-074d3">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/vpa-graph.webp"
      alt="VPA Graph"
       />
  </label>
</p>
<ul>
<li>the system load is low early in the morning, so system resources used by the pod are low.</li>
<li>By 11am, peak load drives a need for more capacity.</li>
<li>The VPA autoscales the pod by adding more system resources (CPU and memory) to meet the demand.</li>
<li>Usage drops in the afternoon, so the pod is autoscaled to use fewer system resources.</li>
<li>And usage drops even lower by 5pm, so the pod is autoscaled further to match the 7am levels.</li>
</ul>
<blockquote>
<p><strong>Note:</strong> You should not use VPAs with HPAs on resource metrics like CPU or memory. However, you can use them together on custom or external metrics.</p></blockquote>
<h3 id="cluster-autoscaler-or-ca">Cluster Autoscaler (or CA)</h3>
<ul>
<li><strong>adjusts</strong> the number of nodes in the cluster when pods fail to schedule, or demand increases or decreases in relation to the existing nodes’ capacity</li>
<li>autoscales the cluster itself, increasing and decreasing the number of available nodes that pods can run on.</li>
<li>Pods are autoscaled using HPA or VPA, but when the nodes themselves are overloaded with pods.</li>
<li>can use a CA to autoscale the nodes so that the pods can rebalance themselves across the cluster.</li>
</ul>
<p>For example,</p>
<p>
  
  <input type="checkbox" id="zoomCheck-49adf" hidden />
  <label for="zoomCheck-49adf">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/ca-graph.webp"
      alt="CA Graph"
       />
  </label>
</p>
<ul>
<li>
<p>the system load is low early in the morning, so existing nodes can handle the load.</p>
</li>
<li>
<p>When demand increases, new pod requests come in, and the CA autoscales the cluster by adding a new node and pods to meet the demand.</p>
</li>
<li>
<p>By 11 am, peak load brings the new node to full capacity.</p>
</li>
<li>
<p>When usage drops in the afternoon, unused pods are marked for deletion and removed.</p>
</li>
<li>
<p>And when usage drops even lower by 5 pm, all pods in the new node are marked for deletion and removed.</p>
</li>
<li>
<p>And then the node itself is marked and removed.</p>
</li>
<li>
<p>cluster autoscaler ensures there is always enough compute power to run your tasks, and that you aren’t paying extra for unused nodes.</p>
</li>
<li>
<p>clusters may have periods where all batch processing jobs are complete, and the new batch doesn’t start until later in the day.</p>
</li>
<li>
<p>Each autoscaler type is suitable in specific scenarios, so you should analyze the pros and cons of each to find the best choice.</p>
</li>
<li>
<p>Using a combination of all three types ensures that</p>
<ul>
<li>services run stably at peak load times, and</li>
<li>costs are minimized in times of lower demand.</li>
</ul>
</li>
</ul>
<h2 id="deployment-strategies">Deployment Strategies</h2>
<ul>
<li>defines an application’s lifecycle that achieves and maintains the configured state for objects and applications in an automated manner. Effective deployment strategies minimize risk.</li>
</ul>
<p>Kubernetes deployment strategies are used to:</p>
<ul>
<li>Deploy, update, or rollback ReplicaSets, Pods, Services, and Applications</li>
<li>Pause/Resume Deployments</li>
<li>Scale Deployments manually or automatically</li>
</ul>
<p>There are are six types of deployment strategies:</p>
<h3 id="recreate">Recreate</h3>
<ul>
<li>is simplest deployment strategy</li>
<li>has short downtime between the shutdown of existing and deployment and the new deployment</li>
<li>Pods running the live version of the application are <strong>all shut down simultaneously</strong>, and a new version of the application is deployed on newly created Pods.</li>
<li>The rollback process is completed in reverse order.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Simple setup</td>
          <td>Short downtime occurs between shutdown and new deployment</td>
      </tr>
      <tr>
          <td>Application version completely replaced</td>
          <td>-</td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-b8326" hidden />
  <label for="zoomCheck-b8326">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/recreate-strategy.webp"
      alt="Recreate Strategy"
       />
  </label>
</p>
<h3 id="rolling-ramped">Rolling (ramped)</h3>
<ul>
<li>each Pod is updated one at a time, single v1 Pod is replaced and is updated in this way until all Pods are v2.</li>
<li>During rollback process, there is hardly any downtime since users are directed to either version.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Simple setup</td>
          <td>Can&rsquo;t control the traffic distribution</td>
      </tr>
      <tr>
          <td>Suitable for stateful applications that need to handle rebalancing of the data</td>
          <td>Rollout/rollback takes time</td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-ac62e" hidden />
  <label for="zoomCheck-ac62e">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/ramped-stretegy.webp"
      alt="Ramped Strategy"
       />
  </label>
</p>
<h3 id="bluegreen">Blue/green</h3>
<ul>
<li>the blue environment is the live version of the application.</li>
<li>the green environment is an exact copy that contains the deployment of the new version of the application.</li>
<li>the green environment is created identical to the current production environment and is thoroughly tested.</li>
<li>once all changes, bugs, and issues are addressed, user traffic is switched from the blue environment to the green environment.</li>
<li>to perform a rollback, switch the environment back.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Instance rollout/rollback (no downtime)</td>
          <td>Expensive(requires double resources)</td>
      </tr>
      <tr>
          <td>New version is available immediately to all users</td>
          <td>Rigorous testing required before releasing to production</td>
      </tr>
      <tr>
          <td></td>
          <td>Handling stateful applications is difficult</td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-2aede" hidden />
  <label for="zoomCheck-2aede">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/blue-green-deployment-strategy.webp"
      alt="Blue and green Deployment Strategy"
       />
  </label>
</p>
<h3 id="canary">Canary</h3>
<ul>
<li>the new version of the application is tested using a small set of random users alongside the current live version of the application.</li>
<li>once the version of the application is successfully tested, it is then rolled out to all users.</li>
<li>rollback has no downtime since few users are exposed to the new version.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Convenient for reliability, error, and performance monitoring</td>
          <td>Slow rollout, gradual user access</td>
      </tr>
      <tr>
          <td>Fast rollback</td>
          <td></td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-5718c" hidden />
  <label for="zoomCheck-5718c">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/canary-strategy.webp"
      alt="Canary Strategy"
       />
  </label>
</p>
<h3 id="ab-testing">A/B testing</h3>
<ul>
<li>known as split testing, evaluates two versions of an application (version A and version B).</li>
<li>each version has features that cater to different sets of users.</li>
<li>can select which version is best for global deployment based on user interaction and feedback.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Multiple versions can run in parallel</td>
          <td>Requires intelligent load balancer</td>
      </tr>
      <tr>
          <td>Full control over traffic distribution</td>
          <td>Difficult to troubleshoot errors for a given session, distributed tracing becomes mandatory</td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-a7786" hidden />
  <label for="zoomCheck-a7786">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/a-b-testing-strategy.webp"
      alt="A/B Testing Strategy"
       />
  </label>
</p>
<h3 id="shadow">Shadow</h3>
<ul>
<li>a &ldquo;shadow version&rdquo; of the application is deployed alongside the live version.</li>
<li>user requests are sent to both versions, and both handle all requests, but the shadow version does not forward responses back to the users.</li>
<li>lets developers see how the shadow version performs using real-world data without interrupting user experience.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Performance testing with production traffic</td>
          <td>Expensive (double resources)</td>
      </tr>
      <tr>
          <td>No user impact</td>
          <td>Not a true user test, can lead to misinterpreted results</td>
      </tr>
      <tr>
          <td>No downtime</td>
          <td>Complex setup</td>
      </tr>
      <tr>
          <td>-</td>
          <td>Require monitoring for two environments</td>
      </tr>
  </tbody>
</table>
<p>
  
  <input type="checkbox" id="zoomCheck-a4058" hidden />
  <label for="zoomCheck-a4058">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/shadow-strategy.webp"
      alt="Shadow Strategy"
       />
  </label>
</p>
<h2 id="comparison">Comparison</h2>
<table>
  <thead>
      <tr>
          <th>Strategy</th>
          <th>Zero Downtime</th>
          <th>Real Traffic Testing</th>
          <th>Targeted Users</th>
          <th>Cloud Cost</th>
          <th>Rollback Duration</th>
          <th>Negative User Impact</th>
          <th>Complexity of Setup</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Recreate</td>
          <td>X</td>
          <td>X</td>
          <td>X</td>
          <td>•&ndash;</td>
          <td>•••</td>
          <td>•••</td>
          <td>- - -</td>
      </tr>
      <tr>
          <td>Ramped</td>
          <td>✓</td>
          <td>X</td>
          <td>X</td>
          <td>•&ndash;</td>
          <td>•••</td>
          <td>•&ndash;</td>
          <td>•&ndash;</td>
      </tr>
      <tr>
          <td>Blue/Green</td>
          <td>✓</td>
          <td>X</td>
          <td>X</td>
          <td>•••</td>
          <td>- - -</td>
          <td>••-</td>
          <td>••-</td>
      </tr>
      <tr>
          <td>Canary</td>
          <td>✓</td>
          <td>✓</td>
          <td>X</td>
          <td>•&ndash;</td>
          <td>•&ndash;</td>
          <td>•&ndash;</td>
          <td>••-</td>
      </tr>
      <tr>
          <td>A/B Testing</td>
          <td>✓</td>
          <td>✓</td>
          <td>✓</td>
          <td>•&ndash;</td>
          <td>•&ndash;</td>
          <td>•&ndash;</td>
          <td>•••</td>
      </tr>
      <tr>
          <td>Shadow</td>
          <td>✓</td>
          <td>✓</td>
          <td>X</td>
          <td>•••</td>
          <td>- - -</td>
          <td>- - -</td>
          <td>•••</td>
      </tr>
  </tbody>
</table>
<p>To create a good strategy:</p>
<ul>
<li>Consider the product type and the target audience</li>
<li>Shadow and canary strategies use live user requests, as opposed to using a sample of users.</li>
<li>The A/B testing strategy is useful if the version of the application requires minor tweaks or UI feature changes.</li>
<li>The blue/green strategy is useful if your version of the application is complex or critical and needs proper monitoring with no downtime during deployment.</li>
<li>The canary strategy is a good choice if you want zero downtime and are comfortable exposing your version of the application to the public.</li>
<li>A rolling strategy gradually deploys the new version of the application. There is no downtime, and it is easy to roll back.</li>
<li>The recreate strategy is a good choice if the application is not critical and users aren’t impacted by a short downtime.</li>
</ul>
<h2 id="rolling-updates">Rolling updates</h2>
<ul>
<li>are automated updates that occur on a scheduled basis.
<ul>
<li>They roll out automated and controlled app changes across pods,</li>
<li>Work with pod templates like deployments, and</li>
<li>allow for rollback as needed.</li>
</ul>
</li>
</ul>
<p>To prepare your application to enable rolling updates,</p>
<ul>
<li>Step 1: Add liveness probes and readiness probes to deployments. That way deployments are appropriately marked as ‘ready.’</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">livenessProbe:
</span></span><span class="line"><span class="cl">  httpGet:
</span></span><span class="line"><span class="cl">    path: /
</span></span><span class="line"><span class="cl">    port: <span class="m">9080</span>
</span></span><span class="line"><span class="cl">  initialDelaySeconds: <span class="m">300</span>
</span></span><span class="line"><span class="cl">  periodSeconds: <span class="m">15</span>
</span></span><span class="line"><span class="cl">readinessProbe:
</span></span><span class="line"><span class="cl">  httpGet:
</span></span><span class="line"><span class="cl">    path: /
</span></span><span class="line"><span class="cl">    port: <span class="m">9080</span>
</span></span><span class="line"><span class="cl">  initialDelaySeconds: <span class="m">45</span>
</span></span><span class="line"><span class="cl">  periodSeconds: <span class="m">5</span>
</span></span></code></pre></div><ul>
<li>Step 2: add a rolling update strategy to the YAML file.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">apiVersion: apps/v1
</span></span><span class="line"><span class="cl">kind: Deployment
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: nginx-test
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  replicas: <span class="m">10</span> <span class="c1"># creating a deployment with 10 pods.</span>
</span></span><span class="line"><span class="cl">  selector:
</span></span><span class="line"><span class="cl">    matchLabels:
</span></span><span class="line"><span class="cl">      service: http-server
</span></span><span class="line"><span class="cl">  <span class="c1"># to wait a few seconds before moving to the next pod in the rollout stage</span>
</span></span><span class="line"><span class="cl">  minReadySeconds: <span class="m">5</span>
</span></span><span class="line"><span class="cl">  progressDeadlineSeconds: <span class="m">600</span>
</span></span><span class="line"><span class="cl">  strategy:
</span></span><span class="line"><span class="cl">    type: RollingUpdate
</span></span><span class="line"><span class="cl">    rollingUpdate:
</span></span><span class="line"><span class="cl">      <span class="c1"># strategy is to have at-least 50% of the pods always available</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># for a zero-downtime system, set the maxUnavailable to 0.</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># Setting the maxSurge to 100% would double the number of pods</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># and create a complete replica before taking the original set down</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># after the rollout is complete.</span>
</span></span><span class="line"><span class="cl">      maxUnavailable: 50%
</span></span><span class="line"><span class="cl">      <span class="c1"># there can only be 2 pods added to the 10 you defined earlier</span>
</span></span><span class="line"><span class="cl">      maxSurge: <span class="m">2</span>
</span></span></code></pre></div><h3 id="rolling-out-an-application-update">Rolling out an application update</h3>
<ul>
<li>Assume, You have a deployment with three pods in your ReplicaSet.</li>
<li>Your application displays the message, “Hello world!”</li>
<li>Your client has submitted a new request, and you have a new image for your application with a different message, “Hello world v2!’ to your users.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-js" data-lang="js"><span class="line"><span class="cl"><span class="c1">// Older
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span> <span class="nx">port</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">PORT</span> <span class="o">||</span> <span class="mi">8080</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">message</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">MESSAGE</span> <span class="o">||</span> <span class="s1">&#39;Hello world!&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Newer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span> <span class="nx">port</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">PORT</span> <span class="o">||</span> <span class="mi">8080</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">message</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">MESSAGE</span> <span class="o">||</span> <span class="s1">&#39;Hello world v2!&#39;</span><span class="p">;</span>
</span></span></code></pre></div><ul>
<li>But you cannot have any downtime in your application.</li>
<li>First, you need to build, tag, and upload this new image to Docker Hub.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker build -t hello-kubernetes .
</span></span><span class="line"><span class="cl">docker tag hello-kubernetes cham11ng/hello-kubernetes:2.0
</span></span><span class="line"><span class="cl">docker push cham11ng/hello-kubernetes:2.0
</span></span><span class="line"><span class="cl"><span class="c1"># Your new software has been dockerized</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and then updated to Docker Hub with the name</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and tag cham11ng/hello-kubernetes:2.0”.</span>
</span></span></code></pre></div><ul>
<li>Second, apply the new image to your deployment.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get deployments
</span></span><span class="line"><span class="cl"><span class="c1"># sets the image flag to the updated tag image on Docker Hub</span>
</span></span><span class="line"><span class="cl">kubectl <span class="nb">set</span> image deployments/hello-kubernetes <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  hello-kubernetes<span class="o">=</span>cham11ng/hello-kubernetes:2.0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  deployment.extensions/hello-kubernetes image updated
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># observe that version 2 deployment has been rollout</span>
</span></span><span class="line"><span class="cl">kubectl rollout status deployments/hello-kubernetes
</span></span><span class="line"><span class="cl">  deployment <span class="s2">&#34;hello-kubernetes&#34;</span> successfully rolled out.
</span></span></code></pre></div><ul>
<li>Third, you can roll back your changes using the &ldquo;rollout undo&rdquo; command if there are errors in a deployment or the clients can change their minds.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl rollout undo deployments/hello-kubernetes
</span></span><span class="line"><span class="cl">  deployment.extensions/hello-kubernetes rolled back
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl"><span class="c1"># we see three new pods that were created as port of the rollback</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and can see some pods in terminating status</span>
</span></span></code></pre></div><h3 id="how-rolling-works">How rolling works</h3>
<h4 id="all-at-once">All-at-once</h4>
<p>In an <strong>all-at-once rollout</strong>, all v1 objects must be removed before v2 objects can become active.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-564b5" hidden />
  <label for="zoomCheck-564b5">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/all-at-once-rollout.webp"
      alt="All-at-once rollout"
       />
  </label>
</p>
<ul>
<li>Here you see version 1 of an app with three pods running that users can access.</li>
<li>When version 2 is deployed, new pods are created.</li>
<li>The version 1 pods are marked for deletion and removed and user access is blocked.</li>
<li>Once the version 1 pods are removed, the version 2 pods become active and user access is restored.</li>
<li>Notice the time lag between deployment and pod updates.</li>
</ul>
<p>In an <strong>all-at-once rollback</strong>, all v2 objects must be removed before v1 objects can become active.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-e00f0" hidden />
  <label for="zoomCheck-e00f0">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/all-at-once-rollback.webp"
      alt="All-at-once rollback"
       />
  </label>
</p>
<ul>
<li>Here you see version 2 of an app with three pods running that users can access.</li>
<li>When version 1 of the app is deployed, new pods are created.</li>
<li>The version 2 pods are marked for deletion and removed and user access is blocked.</li>
<li>Once the version 2 pods are removed, the version 1 pods become active and user access is restored.</li>
</ul>
<h4 id="one-at-a-time">One-at-a-time</h4>
<p>In a <strong>one-at-a-time rollout</strong>, the update is staggered so user access is not interrupted.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-ffaac" hidden />
  <label for="zoomCheck-ffaac">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/one-at-a-time-rollout.webp"
      alt="One-at-a-time rollout"
       />
  </label>
</p>
<ul>
<li>Here you see version 1 of an app with three running pods that users can access.</li>
<li>When version 2 is deployed, a new pod is created.</li>
<li>The first version 1 pod is marked for deletion and removed, and the v2 pod becomes active.</li>
<li>Now, a second v2 pod is created, and the second version 1 pod is marked for deletion and removed, and the second v2 pod becomes active.</li>
<li>Then, a third v2 pod is created, and the third version 1 pod is marked for deletion and removed. And now the third v2 pod becomes active.</li>
</ul>
<p>In a <strong>one-at-a-time rollback</strong>, the update rollback is staggered so user access is not interrupted.</p>
<p>
  
  <input type="checkbox" id="zoomCheck-8f727" hidden />
  <label for="zoomCheck-8f727">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/one-at-a-time-rollback.webp"
      alt="One-at-a-time rollback"
       />
  </label>
</p>
<ul>
<li>Here you see version 2 of an app with three running pods that users can access.</li>
<li>When version 1 of the app is deployed, a new pod is created.</li>
<li>The first version 2 pod is marked for deletion and removed, and the v1 pod becomes active.</li>
<li>Now, a second v1 pod is created. The second version 2 pod is marked for deletion and removed, and the second v1 pod becomes active.</li>
<li>Then, a third v1 pod is created, and the third version 2 pod is marked for deletion and removed. And the third v1 pod becomes active.</li>
</ul>
<h2 id="configmaps">ConfigMaps</h2>
<ul>
<li>helps developers avoid hard coding configuration variables in application code by keeping the configuration variables separate so that any changes in configuration settings do not require code changes.</li>
<li>is an API object that stores non-confidential data in key-value pairs.</li>
<li>provides configuration data to pods and deployments so that the configuration data is not hard coded inside the application code</li>
<li>is meant for non-sensitive information as they do not provide secrecy or encryption.</li>
<li>The data stored in a ConfigMap is limited and cannot exceed 1 megabyte
<ul>
<li>For larger amounts of data, consider mounting a volume or use a separate database or file service</li>
</ul>
</li>
<li>has optional data and binaryData fields and no “spec&quot; field in the template</li>
<li>the Config name must be a valid DNS subdomain name</li>
<li>A ConfigMap is reusable for multiple deployments, thus decoupling the environment from the deployments themselves!</li>
<li>Multiple ways to create
<ul>
<li>a ConfigMap by using string literals,</li>
<li>by using an existing “properties” or ”key” = “value” file,</li>
<li>or by providing a ConfigMap YAML descriptor file. You can use the first and second ways to help create such a YAML file.</li>
</ul>
</li>
<li>Multiple ways to reference from pod/deployment to consume a ConfigMap
<ul>
<li>reference by using environment variables with the configMapKeyRef attribute</li>
<li>by mounting a file using the volumes plugin. (mount as volume)</li>
</ul>
</li>
<li>Kubernetes applies the ConfigMap to the pod or the deployment just before running the pod or deployment.</li>
</ul>
<h3 id="configuration-environment-variable">Configuration: Environment Variable</h3>
<ul>
<li>You’ll use the environment variable directly in the YAML file.</li>
<li>Apply this deployment descriptor to our deployment.</li>
<li>Here, the message is hard-coded in the descriptor file.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">cham11ng/myapp:latest</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c"># is used in the JavaScript file as process.env.MESSAGE</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MESSAGE</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Hello from config file!&#39;</span><span class="w">
</span></span></span></code></pre></div><h3 id="configuration-configmap-string-literal">Configuration: ConfigMap string literal</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># provide a ConfigMap is to provide a key-value pair</span>
</span></span><span class="line"><span class="cl"><span class="c1"># in the create ConfigMap command.</span>
</span></span><span class="line"><span class="cl">kubectl create ConfigMap my-config <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --from-literal<span class="o">=</span><span class="nv">MESSAGE</span><span class="o">=</span><span class="s2">&#34;hello from first configmap&#34;</span>
</span></span></code></pre></div><p>After this first step, the second step is to tell our deployment about the new MESSAGE variable and specify its location for pickup.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MESSAGE</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w"> </span><span class="c"># to point to the ConfigMap created in the first step</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">configMapKeyRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c"># the deployment will look for a key named</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c"># MESSAGE in the ConfigMap named “my-config.”</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">MESSAGE</span><span class="w">
</span></span></span></code></pre></div><h3 id="configuration-configmap-properties-file">Configuration: ConfigMap properties file</h3>
<ul>
<li>Another way to add the MESSAGE variable in the ConfigMap is to use a file that contains all environment variables in the “key=value” format.</li>
<li>Such a file is useful for adding many variables instead of listing those variables one by one on the command line.</li>
<li>Here is a file with just one MESSAGE key and a value “hello from the my.properties file.”</li>
<li>If you specify a directory to the “&ndash;from-file” flag, the entire directory is loaded into the ConfigMap.</li>
<li>You can also load a specific file with a key by using the “&ndash;from-file=key=filename” format.</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl create cm my-config --from-file<span class="o">=</span>my.properties
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">cat my.properties
</span></span><span class="line"><span class="cl">  <span class="m">1</span> <span class="nv">MESSAGE</span><span class="o">=</span>hello from my.properties file
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># to get the YAML output</span>
</span></span><span class="line"><span class="cl">kubectl describe ConfigMap my-config
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MESSAGE</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">configMapKeyRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">my.properties</span><span class="w">
</span></span></span></code></pre></div><h3 id="configuration-configmap-yaml">Configuration: ConfigMap YAML</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">data</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">my.properties</span><span class="p">:</span><span class="w"> </span><span class="l">MESSAGE=hello from the my.properties file</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ConfigMap</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get ConfigMap
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl apply -f my-config.yaml
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl describe cm my-config
</span></span></code></pre></div><ul>
<li>In our case, we have saved the output from ”kubectl get ConfigMap” as a YAML file called “my-config.yaml.”</li>
<li>The first command indicates that there is no ConfigMap to begin with. Here you are creating the ConfigMap.yaml file.</li>
<li>You’ll now apply the YAML file to your cluster which creates the ConfigMap.</li>
<li>Note the MESSAGE in the ConfigMap file description.</li>
</ul>
<h2 id="secrets">Secrets</h2>
<ul>
<li>working with a Secret is like working with a ConfigMap</li>
</ul>
<h3 id="secret-use-with-string-literals">Secret: Use with string literals</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># First, create a secret using a string literal.</span>
</span></span><span class="line"><span class="cl">kubectl create secret generic api-creds <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --from-literal<span class="o">=</span><span class="nv">key</span><span class="o">=</span>mysupersecretapikey
</span></span><span class="line"><span class="cl"><span class="c1"># the get command verifies that the secret was created</span>
</span></span><span class="line"><span class="cl">kubectl get secret
</span></span><span class="line"><span class="cl"><span class="c1"># use the DESCRIBE command to verify our secret is indeed a secret</span>
</span></span><span class="line"><span class="cl"><span class="c1"># and check that you don’t see any secret, written using displayed text</span>
</span></span><span class="line"><span class="cl">kubectl describe secret api-creds
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl get secret api-creds -o YAML
</span></span></code></pre></div><h3 id="secret-use-with-environment-variables">Secret: use with environment variables</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">env</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">API_CREDS</span><span class="w"> </span><span class="c"># process.env.API_CREDS</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">secretKeyRef</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">api-creds</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">key</span><span class="w">
</span></span></span></code></pre></div><h3 id="secret-use-with-volume-mounts">Secret: use with volume mounts</h3>
<ul>
<li>Each container in the descriptor file has its own volumeMount but shares the volume</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl create secret generic api-creds <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --from-literal<span class="o">=</span><span class="nv">key</span><span class="o">=</span>mysupersecretapikey
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hello-kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">cham11ng/myapp:latest</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="c"># use a volume for the secret with a corresponding volumeMount</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">api-creds</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="c"># The api-creds secret is mounted as a file at /etc/api/api-creds</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/etc/api&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">readOnly</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">api-creds</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">secrets</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="l">api-creds</span><span class="w">
</span></span></span></code></pre></div><h2 id="service-binding">Service Binding</h2>
<ul>
<li>is the process needed to consume external Services or backing Services, including REST APIs, databases, and event buses in our applications.</li>
<li>manages configuration and credentials for back-end Services while protecting sensitive data.</li>
<li>In addition, Service binding makes Service credentials available to you automatically as a Secret.</li>
<li>consumes the external Service by binding the application to a deployment.</li>
<li>Then, the application code uses the credentials from the binding and calls the corresponding Service.</li>
<li>Here you can see an architectural diagram that illustrates the binding of a Kubernetes Cluster to an external Service.</li>
<li>Next, let&rsquo;s learn the steps required to bind the Service to your application.</li>
</ul>
<h3 id="architecture">Architecture</h3>
<p>
  
  <input type="checkbox" id="zoomCheck-c32f8" hidden />
  <label for="zoomCheck-c32f8">
    <img
      class="zoomCheck"
      loading="lazy"
      decoding="async"
      src="img/service-binding-architecture.webp"
      alt="Service Binding Architecture"
       />
  </label>
</p>
<h3 id="ibm-service-binding">IBM Service binding</h3>
<ul>
<li>Service binding quickly creates Service credentials for an IBM Cloud Service.</li>
<li>You create the Service credentials using IBM’s public cloud Service endpoint and then store or “bind” your Service credentials in a Kubernetes Secret in your Cluster.</li>
<li>Here’s how to bind an IBM Cloud Service to your Cluster:
<ol>
<li>Provision an instance of the Service</li>
<li>Bind the Service to your Cluster to create Service credentials for your Service that use the public cloud Service endpoint</li>
<li>Store and retrieve the Service credentials in a Kubernetes Secret</li>
<li>Configure your app to access the Service credentials in the Kubernetes Secret</li>
</ol>
</li>
</ul>
<h2 id="commands">Commands</h2>
<table>
  <thead>
      <tr>
          <th>Command</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>kubectl autoscale deployment</td>
          <td>Autoscales a Kubernetes Deployment.</td>
      </tr>
      <tr>
          <td>kubectl create configmap</td>
          <td>Creates a ConfigMap resource.</td>
      </tr>
      <tr>
          <td>kubectl get deployments -o wide</td>
          <td>Lists deployments with details.</td>
      </tr>
      <tr>
          <td>kubectl get hpa</td>
          <td>Lists Horizontal Pod Autoscalers (hpa)</td>
      </tr>
      <tr>
          <td>kubectl scale deployment</td>
          <td>Scales a deployment.</td>
      </tr>
      <tr>
          <td>kubectl set image deployment</td>
          <td>Updates the current deployment.</td>
      </tr>
      <tr>
          <td>kubectl rollout</td>
          <td>Manages the rollout of a resource.</td>
      </tr>
      <tr>
          <td>kubectl rollout restart</td>
          <td>Restarts the resource so that the containers restart.</td>
      </tr>
      <tr>
          <td>kubectl rollout undo</td>
          <td>Rollbacks the resource.</td>
      </tr>
  </tbody>
</table>
]]></content:encoded>
    </item>
  </channel>
</rss>
